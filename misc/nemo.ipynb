{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\s2t\\.nemo\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-06 10:42:43 mixins:196] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2024-05-06 10:42:43 mixins:330] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n",
      "[NeMo I 2024-05-06 10:42:43 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-06 10:42:43 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-06 10:42:43 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-06 10:42:43 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-06 10:42:43 aggregate_tokenizer:72] Aggregate vocab size: 4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-06 10:42:43 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    batch_size: null\n",
      "    num_workers: 8\n",
      "    use_lhotse: true\n",
      "    max_duration: 40\n",
      "    pin_memory: true\n",
      "    use_bucketing: false\n",
      "    bucket_duration_bins: null\n",
      "    num_buckets: 1\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    batch_duration: 360\n",
      "    quadratic_duration: 15\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2024-05-06 10:42:43 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n",
      "[NeMo W 2024-05-06 10:42:43 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-06 10:42:43 features:305] PADDING: 0\n",
      "[NeMo I 2024-05-06 10:42:49 save_restore_connector:263] Model EncDecMultiTaskModel was successfully restored from C:\\Users\\vilyi\\.cache\\huggingface\\hub\\models--nvidia--canary-1b\\snapshots\\b9993c06425b28d3d14bdaaf38437153bc4ba30b\\canary-1b.nemo.\n",
      "[NeMo I 2024-05-06 10:42:49 aed_multitask_models:255] Changed decoding strategy to \n",
      "    strategy: beam\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    compute_langs: false\n",
      "    beam:\n",
      "      beam_size: 1\n",
      "      search_type: default\n",
      "      len_pen: 1.0\n",
      "      max_generation_delta: 20\n",
      "      return_best_hypothesis: true\n",
      "      preserve_alignments: false\n",
      "    temperature: 1.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "# from nemo.collections.asr.models import EncDecMultiTaskModel\n",
    "# asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(\"nvidia/stt_de_conformer_transducer_large\")\n",
    "\n",
    "# asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-1.1b\")\n",
    "\n",
    "asr_model = nemo_asr.models.EncDecMultiTaskModel.from_pretrained('nvidia/canary-1b')\n",
    "# update dcode params\n",
    "decode_cfg = asr_model.cfg.decoding\n",
    "decode_cfg.beam.beam_size = 1\n",
    "asr_model.change_decoding_strategy(decode_cfg)\n",
    "\n",
    "# asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name=\"stt_de_conformer_ctc_medium\")\n",
    "# \n",
    "# asr_model = nemo_asr.models.EncDecHybridRNNTCTCBPEModel.from_pretrained(model_name=\"stt_multilingual_fastconformer_hybrid_large_pc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016677408"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in asr_model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofile = r\"D:\\Database\\s2t-yt\\source\\xJCfhai9kzc\\segments\\segment_08.mp3\"\n",
    "transcript = r\"D:\\Database\\s2t-yt\\source\\xJCfhai9kzc\\transcripts\\segment_08.txt\"    \n",
    "text = open(transcript, 'r', encoding='utf-8').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:14, 14.24s/it]\n"
     ]
    }
   ],
   "source": [
    "predicted_text  = asr_model.transcribe([audiofile], \n",
    "                                       source_lang='de', \n",
    "                                       target_lang='de',\n",
    "                                       pnc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich, Ali, hatte vielleicht 4 ausl채ndische Mitsch체ler in der Klasse. Der Rest war alles Deutsche. Ich hab jetzt mal meinen Neffen abgeholt,'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich , Ali , hatte vielleicht vier ausl채ndische Mitsch체ler in der Klasse , Der Rest war alles Deutsche . Ich habe mir das noch mal beim Neffen abgeholt .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5517)\n",
      "tensor(0.1846, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torcheval.metrics import WordErrorRate, BLEUScore, Perplexity\n",
    "\n",
    "wer = WordErrorRate()\n",
    "wer.update(text, predicted_text[0])\n",
    "print(wer.compute())\n",
    "\n",
    "bleu = BLEUScore(n_gram=4)\n",
    "bleu.update(text, predicted_text)\n",
    "print(bleu.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
